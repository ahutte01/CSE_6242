{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DB0vv4pBcWu9"
   },
   "source": [
    "# Q3 Using Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GalZFbfhcWvA"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import gc\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, cross_validate, train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r8CbpTPx9rKA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ahutter6\n"
     ]
    }
   ],
   "source": [
    "# Change to your GA Tech ID\n",
    "ga_id = 'ahutter6'\n",
    "# Requires a print() statement do not modify below print statement\n",
    "print(ga_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2Z1gV3UlcWvD"
   },
   "source": [
    "# Q3.1 Data Import and Cleansing Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9VS44b2kcWvE"
   },
   "outputs": [],
   "source": [
    "# XXX\n",
    "# TODO: Read in all the data. Replace the 'xxx' with the path to the data set. We've started this for you. \n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "data = pd.read_csv('pulsar_stars.csv')\n",
    "# -------------------------------\n",
    "\n",
    "# XXX\n",
    "# TODO: Separate out the x_data and y_data. We've started this for you.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "x_data = data.loc[:,['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8']]\n",
    "#x_data = data.iloc[:, :-1]\n",
    "\n",
    "y_data = data.loc[:,'y']\n",
    "\n",
    "# -------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xuEypbCqcWvG"
   },
   "outputs": [],
   "source": [
    "# XXX\n",
    "# TODO: Split 70% of the data into training and 30% into test sets. Call them x_train, x_test, y_train and y_test.\n",
    "# Use the train_test_split method in sklearn with the parameter 'shuffle' set to true and the 'random_state' \n",
    "# set to 614.\n",
    "# \n",
    "\n",
    "# -------------------------------\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size = .30, train_size = .70, random_state = 614, shuffle = True)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q09V5Ux5cWvI"
   },
   "source": [
    "# Q3.2 Linear Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tnHXBF1UcWvJ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Create a LinearRegression classifier and train it.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "linregressor = LinearRegression()\n",
    "linregressor.fit(x_train, y_train)\n",
    "# \n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "McSbfk9WcWvL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9720625798212005\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Test its accuracy (on the training set) using the accuracy_score method.\n",
    "# Note: Round the output values greater than or equal to 0.5 to 1 and those less than 0.5 to 0. You can use any method that satisfies the requriements.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "y_train_pred = linregressor.predict(x_train)\n",
    "#print(y_train_pred)\n",
    "\n",
    "y_train_pred = np.where(y_train_pred < .50, 0, 1)\n",
    "#print(y_train_pred)\n",
    "\n",
    "print(accuracy_score(y_true = y_train, y_pred = y_train_pred))\n",
    "\n",
    "# Requires a print() statement\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VgySbn7xcWvN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9696461824953445\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Test its accuracy (on the testing set) using the accuracy_score method.\n",
    "# Note: Round the output values greater than or equal to 0.5 to 1 and those less than 0.5 to 0. You can use any method that satisfies the requriements.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "y_test_pred = linregressor.predict(x_test)\n",
    "\n",
    "y_test_pred = np.where(y_test_pred < .50, 0, 1)\n",
    "\n",
    "print(accuracy_score(y_true = y_test, y_pred = y_test_pred))\n",
    "# Requires a print() statement\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WbqnCyHAcWvP"
   },
   "source": [
    "# Q3.3 Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dTtIFJW7cWvQ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=614,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Create a RandomForestClassifier and train it.\n",
    "# Set 'random_state' to 614\n",
    "# XXX\n",
    "rfclassifier = RandomForestClassifier(random_state = 614)\n",
    "rfclassifier.fit(x_train, y_train)\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IWeNJLzqcWvS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Test its accuracy on the training set using the accuracy_score method.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "y_train_pred = rfclassifier.predict(x_train)\n",
    "\n",
    "print(accuracy_score(y_true = y_train, y_pred = y_train_pred))\n",
    "# Requires a print() statement\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wsMXeLyncWvU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9800744878957169\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Test its accuracy on the test set using the accuracy_score method.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "y_test_pred = rfclassifier.predict(x_test)\n",
    "\n",
    "print(accuracy_score(y_true = y_test, y_pred = y_test_pred))\n",
    "# Requires a print() statement\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uEkwb0M3cWvW"
   },
   "source": [
    "## Q3.3.1 Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YmjevLlPcWvW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2229389  0.04576524 0.31748998 0.19307467 0.07611149 0.04671938\n",
      " 0.05356464 0.0443357 ]\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Determine the feature importance as evaluated by the Random Forest Classifier.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "print(rfclassifier.feature_importances_)\n",
    "# Requires a print() statement\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8XcRI7kUcWvY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0 3 4 6 5 1 7]\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Sort them in the descending order and print the feature numbers[0 to ...].\n",
    "#       Hint: There is a direct function available in sklearn to achieve this. Also checkout argsort() function in Python.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "importance = rfclassifier.feature_importances_\n",
    "indices = np.argsort(importance)[::-1] # This switches from Ascending to Desceding; overrides the default \n",
    "print(indices)\n",
    "# Requires a print() statement\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1AlCc_E3cWva"
   },
   "source": [
    "## Q3.3.2 Hyper-parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y3fjpmWLcWvb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              oob_score=False, random_state=614,\n",
       "                                              verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'max_depth': [2, 8, 16], 'n_estimators': [4, 16, 256]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Tune the hyper-parameters 'n_estimators' and 'max_depth'.\n",
    "# 'n_estimators': [4, 16, 256]\n",
    "# 'max_depth': [2, 8, 16]\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "\n",
    "#rfclassifier.get_params()\n",
    "param_grid = {'n_estimators': [4, 16, 256],\n",
    "              'max_depth': [2, 8, 16]}\n",
    "\n",
    "rf_grid = GridSearchCV(estimator = rfclassifier, param_grid = param_grid)\n",
    "rf_grid.fit(x_train, y_train) # only use training sets per Piazza \n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y0OaHSCRcWvc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 16, 'n_estimators': 256}\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Get the best params, using .best_params_\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "print(rf_grid.best_params_)\n",
    "# Requires a print() statement\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eyXkkZr9cWve"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9798049551336275\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Get the best score, using .best_score_.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "print(rf_grid.best_score_)\n",
    "# Requires a print() statement\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BNeOPWIpcWvg"
   },
   "source": [
    "# Q3.4 Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CN3Wkw7zcWvh"
   },
   "source": [
    "## Q3.4.1 Pre-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9msZXyImcWvh"
   },
   "outputs": [],
   "source": [
    "# XXX\n",
    "# TODO: Pre-process the data to standardize it, otherwise the grid search will take much longer.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "scaler_x = StandardScaler()\n",
    "scaler_x.fit(x_train)\n",
    "#print(scaler_x.mean_)\n",
    "x_train = scaler_x.transform(x_train)\n",
    "x_test = scaler_x.transform(x_test)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pqz1htxM9rLO"
   },
   "source": [
    "## Q3.4.2 Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g_nrOJdIcWvj"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Create a SVC classifier and train it.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "svm = SVC()\n",
    "svm.fit(x_train, y_train)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U40EOPEecWvl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9802043422733078\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Test its accuracy on the training set using the accuracy_score method.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "y_train_pred = svm.predict(x_train)\n",
    "\n",
    "print(accuracy_score(y_true = y_train, y_pred = y_train_pred))\n",
    "# Requires a print() statement\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x_jidMDvcWvm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9757914338919925\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Test its accuracy on the test set using the accuracy_score method.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "\n",
    "y_test_pred = svm.predict(x_test)\n",
    "\n",
    "print(accuracy_score(y_true = y_test, y_pred = y_test_pred))\n",
    "# Requires a print() statement\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "89N3JURqcWvp"
   },
   "source": [
    "## Q3.4.3 Hyper-parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ufWB_j_-cWvq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
       "                           class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='scale', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'C': [0.01, 0.1, 1.0], 'kernel': ['linear', 'rbf']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Tune the hyper-parameters 'C' and 'kernel' (use rbf and linear).\n",
    "# 'kernel':('linear', 'rbf') \n",
    "# 'C':[0.01, 0.1, 1.0]\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "param_grid = {'kernel': ['linear', 'rbf'],\n",
    "              'C': [0.01, 0.1, 1.0]}\n",
    "svm_grid = GridSearchCV(estimator = svm, param_grid = param_grid, n_jobs = -1, return_train_score = True)\n",
    "svm_grid.fit(x_train, y_train)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dYsFkceBcWvu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9798849547513114\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Get the best score, using .best_score_.\n",
    "# Note: Set n_jobs=-1 and return_train_score=True\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "print(svm_grid.best_score_)\n",
    "# Requires a print() statement\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_i1BM7zQcWvw"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Calculate the training and test set accuracy values after hyperparameter tuning and standardization. \n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "#print(svm_grid.best_params_)\n",
    "# use C = 1.0, kernel = 'linear'\n",
    "svm_best = SVC(C=1.0, kernel='linear')\n",
    "svm_best.fit(x_train, y_train)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_UzWph6Y9rLs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9797254150702427\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Test its accuracy (on the training set) using the accuracy_score method.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "y_train_pred = svm_best.predict(x_train)\n",
    "\n",
    "print(accuracy_score(y_true = y_train, y_pred = y_train_pred))\n",
    "# Requires a print() statement\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gSQXwaDn9rLw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9778398510242086\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Test its accuracy (on the test set) using the accuracy_score method.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "y_test_pred = svm_best.predict(x_test)\n",
    "\n",
    "print(accuracy_score(y_true = y_test, y_pred = y_test_pred))\n",
    "# Requires a print() statement\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Io4IVbup9rL1"
   },
   "source": [
    "## Q3.4.4 Cross Validation Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1kVfAqsbcWv1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 6 3 4 1 2]\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Get the rank test score for all hyperparameter values that you obtained in Q3.4.3. The \n",
    "# GridSearchCV class holds a  ‘cv_results_’ dictionary that should help you report these metrics easily.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "#print(svm_grid.cv_results_)\n",
    "print(svm_grid.cv_results_['rank_test_score'])\n",
    "# Requires a print() statement\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2UrUu1DXcWv2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.97597358 0.9699073  0.97876735 0.97788907 0.97988495 0.97940588]\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Get the mean testing score for all of hyperparameter values that you obtained in Q3.4.3. The \n",
    "# GridSearchCV class holds a  ‘cv_results_’ dictionary that should help you report these metrics easily.\n",
    "# XXX\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "print(svm_grid.cv_results_['mean_test_score'])\n",
    "# Requires a print() statement\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c2qDYMjgcWv5"
   },
   "source": [
    "# Q3.5 PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-C9BuGsqcWv5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=8, random_state=None,\n",
       "    svd_solver='full', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Perform dimensionality reduction of the data using PCA.\n",
    "#       Set parameters n_component to 8 and svd_solver to 'full'. Keep other parameters at their default value.\n",
    "# XXX\n",
    "\n",
    "# NOTE: Use the full x data set for this section 'x_data'\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "pca = PCA(n_components = 8, svd_solver = 'full')\n",
    "pca.fit(x_data)\n",
    "# You should see an output here of PCA(copy=True....)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CZCJCtGhcWv7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.71053041e-01 7.81934383e-02 4.11562290e-02 6.15967691e-03\n",
      " 2.43717952e-03 9.58578490e-04 3.90570992e-05 2.79968662e-06]\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Get percentage of variance explained by each of the selected components\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "print(pca.explained_variance_ratio_)\n",
    "# Requires a print() statement\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y9nPDDyTcWv8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14430.28004546  4323.5214088   3136.68022725  1213.47665361\n",
      "   763.30168073   478.70316467    96.62788002    25.87063984]\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Get the singular values corresponding to each of the selected components.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "print(pca.singular_values_)\n",
    "# Requires a print() statement\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "hw4q3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
